{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUE-CLUENER 细粒度命名实体识别\n",
    "\n",
    "本数据是在清华大学开源的文本分类数据集THUCTC基础上，选出部分数据进行细粒度命名实体标注，原数据来源于Sina News RSS.\n",
    "\n",
    "训练集：10748 验证集：1343\n",
    "\n",
    "标签类别：\n",
    "数据分为10个标签类别，分别为: 地址（address），书名（book），公司（company），游戏（game），政府（goverment），电影（movie），姓名（name），组织机构（organization），职位（position），景点（scene）\n",
    "\n",
    "数据下载地址：https://github.com/CLUEbenchmark/CLUENER2020\n",
    "\n",
    "排行榜地址：https://cluebenchmarks.com/ner.html\n",
    "\n",
    "|模型|线上效果f1|\n",
    "|------|------:|\n",
    "|Bert-base|78.82|\n",
    "|RoBERTa-wwm-large-ext|80.42|\n",
    "|Bi-Lstm + CRF|70.00|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "seg_len=0\n",
    "seg_backoff=0\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/rawdata/train.json'\n",
    "test_file = './data/rawdata/test.json'\n",
    "dev_file = './data/rawdata/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(json_file):\n",
    "    rd = open(json_file, 'r')\n",
    "    lines = rd.readlines()\n",
    "    rd.close()\n",
    "    json_data = []\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        line_data = json.loads(line)\n",
    "        json_data.append(line_data)\n",
    "    print(f\"Total: {len(json_data)}\")\n",
    "    print(json_data[:5])\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10748/10748 [00:00<00:00, 87197.78it/s]\n",
      "100%|██████████| 1345/1345 [00:00<00:00, 289047.44it/s]\n",
      "100%|██████████| 1343/1343 [00:00<00:00, 22562.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10748\n",
      "[{'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，', 'label': {'name': {'叶老桂': [[9, 11]]}, 'company': {'浙商银行': [[0, 3]]}}}, {'text': '生生不息CSOL生化狂潮让你填弹狂扫', 'label': {'game': {'CSOL': [[4, 7]]}}}, {'text': '那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？', 'label': {'organization': {'那不勒斯': [[0, 3]], '锡耶纳': [[6, 8]], '桑普': [[11, 12]], '热那亚': [[15, 17]]}}}, {'text': '加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》，', 'label': {'movie': {'加勒比海盗3：世界尽头》': [[0, 11]], '《变形金刚》': [[33, 38]]}}}, {'text': '布鲁京斯研究所桑顿中国中心研究部主任李成说，东亚的和平与安全，是美国的“核心利益”之一。', 'label': {'address': {'美国': [[32, 33]]}, 'organization': {'布鲁京斯研究所桑顿中国中心': [[0, 12]]}, 'name': {'李成': [[18, 19]]}, 'position': {'研究部主任': [[13, 17]]}}}]\n",
      "Total: 1345\n",
      "[{'id': 0, 'text': '四川敦煌学”。近年来，丹棱县等地一些不知名的石窟迎来了海内外的游客，他们随身携带着胡文和的著作。'}, {'id': 1, 'text': '尼日利亚海军发言人当天在阿布贾向尼日利亚通讯社证实了这一消息。'}, {'id': 2, 'text': '销售冠军：辐射3-Bethesda'}, {'id': 3, 'text': '所以大多数人都是从巴厘岛南部开始环岛之旅。'}, {'id': 4, 'text': '备受瞩目的动作及冒险类大作《迷失》在其英文版上市之初就受到了全球玩家的大力追捧。'}]\n",
      "Total: 1343\n",
      "[{'text': '彭小军认为，国内银行现在走的是台湾的发卡模式，先通过跑马圈地再在圈的地里面选择客户，', 'label': {'address': {'台湾': [[15, 16]]}, 'name': {'彭小军': [[0, 2]]}}}, {'text': '温格的球队终于又踢了一场经典的比赛，2比1战胜曼联之后枪手仍然留在了夺冠集团之内，', 'label': {'organization': {'曼联': [[23, 24]]}, 'name': {'温格': [[0, 1]]}}}, {'text': '突袭黑暗雅典娜》中Riddick发现之前抓住他的赏金猎人Johns，', 'label': {'game': {'突袭黑暗雅典娜》': [[0, 7]]}, 'name': {'Riddick': [[9, 15]], 'Johns': [[28, 32]]}}}, {'text': '郑阿姨就赶到文汇路排队拿钱，希望能将缴纳的一万余元学费拿回来，顺便找校方或者教委要个说法。', 'label': {'address': {'文汇路': [[6, 8]]}}}, {'text': '我想站在雪山脚下你会被那巍峨的雪山所震撼，但你一定要在自己身体条件允许的情况下坚持走到牛奶海、', 'label': {'scene': {'牛奶海': [[43, 45]], '雪山': [[4, 5]]}}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = load_json_data(train_file)\n",
    "test_data = load_json_data(test_file)\n",
    "dev_data = load_json_data(dev_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 样本数量分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + dev_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 样本长度分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12091/12091 [00:00<00:00, 1621996.09it/s]\n",
      "2020-06-16 18:15:09.576 | INFO     | __main__:<module>:2 - ***** Text Lengths *****\n",
      "2020-06-16 18:15:09.578 | INFO     | __main__:<module>:3 - mean: 37.39\n",
      "2020-06-16 18:15:09.579 | INFO     | __main__:<module>:4 - std: 37.39\n",
      "2020-06-16 18:15:09.581 | INFO     | __main__:<module>:5 - max: 50\n",
      "2020-06-16 18:15:09.582 | INFO     | __main__:<module>:6 - min: 2\n"
     ]
    }
   ],
   "source": [
    "lengths = [ len(x['text']) for x in tqdm(all_data)]\n",
    "logger.info(f\"***** Text Lengths *****\")\n",
    "logger.info(f\"mean: {np.mean(lengths):.2f}\")\n",
    "logger.info(f\"std: {np.mean(lengths):.2f}\")\n",
    "logger.info(f\"max: {np.max(lengths)}\")\n",
    "logger.info(f\"min: {np.min(lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 样本标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12091/12091 [00:00<00:00, 1129372.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'name': 3199, 'position': 2811, 'company': 2494, 'address': 2363, 'game': 2123, 'organization': 2100, 'government': 1651, 'scene': 1070, 'book': 1029, 'movie': 880})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "for text_data in tqdm(all_data):\n",
    "    labels = text_data['label']\n",
    "    for k, v in labels.items():\n",
    "        all_labels.append(k)\n",
    "print(f\"{Counter(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address',\n",
       " 'book',\n",
       " 'company',\n",
       " 'game',\n",
       " 'government',\n",
       " 'movie',\n",
       " 'name',\n",
       " 'organization',\n",
       " 'position',\n",
       " 'scene']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_labels = np.unique(all_labels).tolist()\n",
    "ner_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "from theta.utils import load_json_file, split_train_eval_examples\n",
    "from theta.modeling import LabeledText, load_ner_examples, load_ner_labeled_examples, save_ner_preds, show_ner_datainfo\n",
    "\n",
    "from theta.modeling.ner_span import load_model, NerTrainer, get_args\n",
    "#from theta.modeling.ner import load_model, NerTrainer, get_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 模型输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text:\n",
    "        text = text.strip()\n",
    "        #  text = re.sub('\\t', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def train_data_generator(train_file):\n",
    "\n",
    "    lines = load_json_file(train_file)\n",
    "\n",
    "    for i, x in enumerate(tqdm(lines)):\n",
    "        guid = str(i)\n",
    "        text = clean_text(x['text'])\n",
    "        sl = LabeledText(guid, text)\n",
    "\n",
    "        # -------------------- 训练数据json格式 --------------------\n",
    "        #  {\n",
    "        #      \"text\": \"万通地产设计总监刘克峰；\",\n",
    "        #      \"label\": {\n",
    "        #          \"name\": {\n",
    "        #              \"刘克峰\": [[8, 10]]\n",
    "        #          },\n",
    "        #          \"company\": {\n",
    "        #              \"万通地产\": [[0, 3]]\n",
    "        #          },\n",
    "        #          \"position\": {\n",
    "        #              \"设计总监\": [[4, 7]]\n",
    "        #          }\n",
    "        #      }\n",
    "        #  }\n",
    "\n",
    "        entities = []\n",
    "        classes = x['label'].keys()\n",
    "        for c in classes:\n",
    "            c_labels = x['label'][c]\n",
    "            #  logger.debug(f\"c_labels:{c_labels}\")\n",
    "            for label, span in c_labels.items():\n",
    "                x0, x1 = span[0]\n",
    "                sl.add_entity(c, x0, x1)\n",
    "\n",
    "        yield str(i), text, None, sl.entities\n",
    "\n",
    "\n",
    "def load_train_val_examples(args):\n",
    "    lines = []\n",
    "    for guid, text, _, entities in train_data_generator(args.train_file):\n",
    "        sl = LabeledText(guid, text, entities)\n",
    "        lines.append({'guid': guid, 'text': text, 'entities': entities})\n",
    "\n",
    "    allow_overlap = args.allow_overlap\n",
    "    if args.num_augements > 0:\n",
    "        allow_overlap = False\n",
    "\n",
    "    train_base_examples = load_ner_labeled_examples(\n",
    "        lines,\n",
    "        ner_labels,\n",
    "        seg_len=args.seg_len,\n",
    "        seg_backoff=args.seg_backoff,\n",
    "        num_augements=args.num_augements,\n",
    "        allow_overlap=allow_overlap)\n",
    "\n",
    "    train_examples, val_examples = split_train_eval_examples(\n",
    "        train_base_examples,\n",
    "        train_rate=args.train_rate,\n",
    "        fold=args.fold,\n",
    "        shuffle=True,\n",
    "        random_state=args.seed)\n",
    "\n",
    "    logger.info(f\"Loaded {len(train_examples)} train examples, \"\n",
    "                f\"{len(val_examples)} val examples.\")\n",
    "    return train_examples, val_examples\n",
    "\n",
    "\n",
    "def test_data_generator(test_file):\n",
    "\n",
    "    lines = load_json_file(test_file)\n",
    "    for i, s in enumerate(tqdm(lines)):\n",
    "        guid = str(i)\n",
    "        text_a = clean_text(s['text'])\n",
    "\n",
    "        yield guid, text_a, None, None\n",
    "\n",
    "\n",
    "def load_test_examples(args):\n",
    "    test_base_examples = load_ner_examples(test_data_generator,\n",
    "                                           args.test_file,\n",
    "                                           seg_len=args.seg_len,\n",
    "                                           seg_backoff=args.seg_backoff)\n",
    "\n",
    "    logger.info(f\"Loaded {len(test_base_examples)} test examples.\")\n",
    "    return test_base_examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 模型输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(args):\n",
    "    reviews_file = f\"{args.output_dir}/{args.dataset_name}_reviews_fold{args.fold}.json\"\n",
    "    reviews = json.load(open(reviews_file, 'r'))\n",
    "\n",
    "    submission_file = f\"{args.dataset_name}_predict.json\"\n",
    "    test_results = {}\n",
    "    for guid, json_data in reviews.items():\n",
    "        text = json_data['text']\n",
    "\n",
    "        if guid not in test_results:\n",
    "            test_results[guid] = {\n",
    "                \"guid\": guid,\n",
    "                \"content\": \"\",\n",
    "                \"events\": [],\n",
    "                \"tagged_text\": \"\",\n",
    "            }\n",
    "\n",
    "        s0 = 0\n",
    "        tagged_text = test_results[guid]['tagged_text']\n",
    "        for json_entity in json_data['entities']:\n",
    "            event_type = json_entity['category']\n",
    "            entity_text = json_entity['mention']\n",
    "            s = json_entity['start']\n",
    "            e = json_entity['end']\n",
    "            test_results[guid]['events'].append(\n",
    "                (event_type, entity_text, s, e))\n",
    "\n",
    "            tagged_text += f\"{text[s0:s]}\\n\"\n",
    "            tagged_text += f\"【{event_type} | {entity_text}】\\n\"\n",
    "            test_results[guid]['tagged_text'] = tagged_text\n",
    "            test_results[guid]['content'] += text\n",
    "\n",
    "            s0 = e\n",
    "\n",
    "        test_results[guid]['events'] = sorted(test_results[guid]['events'],\n",
    "                                              key=lambda x: x[3])\n",
    "\n",
    "    json.dump(test_results,\n",
    "              open(f\"{submission_file}\", 'w'),\n",
    "              ensure_ascii=False,\n",
    "              indent=2)\n",
    "\n",
    "    logger.info(f\"Saved {len(reviews)} lines in {submission_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 自定义模型\n",
    "Theta对每类任务都有缺省模型，通常情况下不需要自定义模型。训练器Trainer中传入参数build_model=None即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 自定训练器\n",
    "\n",
    "训练器也不是必须定义的，可以直接用NerTrainer实例化训练器。\n",
    "\n",
    "自定义训练器通常是为了使用自定义模型或重载训练、评估、推理过程的关键节点，便于输出、调试等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Trainer --------------------\n",
    "\n",
    "class AppTrainer(NerTrainer):\n",
    "    def __init__(self, args, ner_labels):\n",
    "        super(AppTrainer, self).__init__(args, ner_labels, build_model=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 主控流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    if args.generate_submission:\n",
    "        generate_submission(args)\n",
    "    else:\n",
    "        trainer = AppTrainer(args, ner_labels)\n",
    "\n",
    "        if args.do_eda:\n",
    "            show_ner_datainfo(ner_labels, train_data_generator,\n",
    "                              args.train_file, test_data_generator,\n",
    "                              args.test_file)\n",
    "\n",
    "        elif args.do_train:\n",
    "            train_examples, val_examples = load_train_val_examples(args)\n",
    "            trainer.train(args, train_examples, val_examples)\n",
    "\n",
    "        elif args.do_eval:\n",
    "            _, eval_examples = load_train_val_examples(args)\n",
    "            model = load_model(args)\n",
    "            trainer.evaluate(args, model, eval_examples)\n",
    "\n",
    "        elif args.do_predict:\n",
    "            test_examples = load_test_examples(args)\n",
    "            model = load_model(args)\n",
    "            trainer.predict(args, model, test_examples)\n",
    "            save_ner_preds(args, trainer.pred_results, test_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def add_special_args(parser):\n",
    "#    return parser\n",
    "\n",
    "#from theta.modeling.glue.args import get_args\n",
    "#args = get_args([add_special_args])\n",
    "\n",
    "import sys, argparse\n",
    "\n",
    "def get_init_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    for arg in sys.argv:\n",
    "        if arg.startswith('-'):\n",
    "            parser.add_argument(arg, type=str)\n",
    "    parser.add_argument('--do_eda', action=\"store_true\")\n",
    "    parser.add_argument('--generate_submission', action=\"store_true\")\n",
    "    parser.add_argument('--allow_overlap', action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "#import argparse\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"-f\",type=str)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "args = get_init_args()\n",
    "FOLD=0\n",
    "DATASET_NAME=\"cluener\"\n",
    "DATA_DIR=\"./data\"\n",
    "OUTPUT_DIR=f\"output_{DATASET_NAME}\"\n",
    "CHECKPOINT_MODEL=f\"{OUTPUT_DIR}/best_fold{FOLD}\"\n",
    "\n",
    "TRAIN_FILE = \"./data/rawdata/train.json\"\n",
    "TEST_FILE = \"./data/rawdata/test.json\"\n",
    "EVAL_FILE = \"./data/rawdata/eval.json\"\n",
    "\n",
    "EPOCHS=3\n",
    "TRAIN_SAMPLE_RATE=1.0\n",
    "\n",
    "MODEL_TYPE=\"bert\"\n",
    "PRETRAINED_MODEL=\"/opt/share/pretrained/pytorch/bert-base-chinese\"\n",
    "LEARNING_RATE=2e-5\n",
    "TRAIN_MAX_SEQ_LENGTH=256\n",
    "EVAL_MAX_SEQ_LENGTH=256\n",
    "TRAIN_BATCH_SIZE=12\n",
    "EVAL_BATCH_SIZE=12\n",
    "PREDICT_BATCH_SIZE=12\n",
    "\n",
    "args.do_train=False\n",
    "args.do_predict=False\n",
    "args.do_eval=False\n",
    "args.train_max_seq_length = TRAIN_MAX_SEQ_LENGTH\n",
    "args.eval_max_seq_length = EVAL_MAX_SEQ_LENGTH\n",
    "args.num_train_epochs = EPOCHS\n",
    "args.learning_rate = LEARNING_RATE\n",
    "args.per_gpu_train_batch_size = TRAIN_BATCH_SIZE\n",
    "args.per_gpu_eval_batch_size = EVAL_BATCH_SIZE\n",
    "args.per_gpu_predict_batch_size = EVAL_BATCH_SIZE\n",
    "\n",
    "args.data_dir = DATA_DIR\n",
    "args.dataset_name = DATASET_NAME\n",
    "args.train_file = TRAIN_FILE\n",
    "args.eval_file = EVAL_FILE\n",
    "args.test_file = TEST_FILE\n",
    "\n",
    "args.output_dir = OUTPUT_DIR\n",
    "args.pred_output_dir = OUTPUT_DIR\n",
    "\n",
    "args.model_type = MODEL_TYPE\n",
    "args.model_path = PRETRAINED_MODEL\n",
    "args.overwrite_cache = True\n",
    "args.train_sample_rate = TRAIN_SAMPLE_RATE\n",
    "args.seed = 8864\n",
    "args.local_rank=-1\n",
    "args.no_cuda = None\n",
    "args.do_lower_case=True\n",
    "args.cache_dir = None\n",
    "args.train_rate=0.8\n",
    "args.fold = 0\n",
    "args.gradient_accumulation_steps = 1\n",
    "args.max_steps = 0\n",
    "args.focalloss_gamma = 1.5\n",
    "args.focalloss_alpha = None\n",
    "args.weight_decay = 0.0\n",
    "args.warmup_rate = 0.1\n",
    "args.fp16 = True\n",
    "args.fp16_opt_level = 'O1'\n",
    "args.max_grad_norm = 1.0\n",
    "args.save_checkpoints = False\n",
    "args.no_eval_on_each_epoch=False\n",
    "args.num_augements = 0\n",
    "args.seg_len = 254\n",
    "args.seg_backoff=64\n",
    "args.enable_kd=False\n",
    "\n",
    "\n",
    "args.soft_label = False\n",
    "args.loss_type = 'CrossEntropyLoss'\n",
    "#args.loss_type = 'FocalLoss'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:22:49.696 | INFO     | theta.modeling.ner_span.trainer:init_labels:283 - args.label2id: {'[unused1]': 0, 'address': 1, 'book': 2, 'company': 3, 'game': 4, 'government': 5, 'movie': 6, 'name': 7, 'organization': 8, 'position': 9, 'scene': 10}\n",
      "2020-06-16 18:22:49.697 | INFO     | theta.modeling.ner_span.trainer:init_labels:284 - args.id2label: {0: '[unused1]', 1: 'address', 2: 'book', 3: 'company', 4: 'game', 5: 'government', 6: 'movie', 7: 'name', 8: 'organization', 9: 'position', 10: 'scene'}\n",
      "2020-06-16 18:22:49.698 | INFO     | theta.modeling.ner_span.trainer:init_labels:285 - args.num_labels: 11\n",
      "100%|██████████| 10748/10748 [00:00<00:00, 32330.91it/s]\n",
      "100%|██████████| 10748/10748 [00:00<00:00, 163443.08it/s]\n",
      "  0%|          | 0/10748 [00:00<?, ?it/s]2020-06-16 18:22:50.151 | WARNING  | theta.modeling.ner_utils:data_seg_generator:287 - Overlap! 1506 mention: 招商银行(16:19), used_span: [(15, 34)]\n",
      "2020-06-16 18:22:50.152 | WARNING  | theta.modeling.ner_utils:data_seg_generator:287 - Overlap! 1506 mention: 永隆银行(23:26), used_span: [(15, 34)]\n",
      "100%|██████████| 10748/10748 [00:00<00:00, 139091.90it/s]\n",
      "2020-06-16 18:22:50.218 | INFO     | theta.modeling.ner_utils:load_ner_labeled_examples:437 - Loaded 10748 examples.\n",
      "2020-06-16 18:22:50.226 | INFO     | __main__:load_train_val_examples:70 - Loaded 8598 train examples, 2150 val examples.\n",
      "2020-06-16 18:22:50.232 | INFO     | theta.modeling.trainer:train:140 - Start train: 8598 train examples, 2150 eval examples.\n",
      "Tokenize:   0%|          | 0/8598 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10748\n",
      "[{'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，', 'label': {'name': {'叶老桂': [[9, 11]]}, 'company': {'浙商银行': [[0, 3]]}}}, {'text': '生生不息CSOL生化狂潮让你填弹狂扫', 'label': {'game': {'CSOL': [[4, 7]]}}}, {'text': '那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？', 'label': {'organization': {'那不勒斯': [[0, 3]], '锡耶纳': [[6, 8]], '桑普': [[11, 12]], '热那亚': [[15, 17]]}}}, {'text': '加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》，', 'label': {'movie': {'加勒比海盗3：世界尽头》': [[0, 11]], '《变形金刚》': [[33, 38]]}}}, {'text': '布鲁京斯研究所桑顿中国中心研究部主任李成说，东亚的和平与安全，是美国的“核心利益”之一。', 'label': {'address': {'美国': [[32, 33]]}, 'organization': {'布鲁京斯研究所桑顿中国中心': [[0, 12]]}, 'name': {'李成': [[18, 19]]}, 'position': {'研究部主任': [[13, 17]]}}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenize: 100%|██████████| 8598/8598 [00:00<00:00, 26317.03it/s]\n",
      "2020-06-16 18:22:51.158 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:151 - all_input_ids.shape: (8598, 256)\n",
      "2020-06-16 18:22:51.282 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:153 - all_attention_mask.shape: (8598, 256)\n",
      "2020-06-16 18:22:51.405 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:155 - all_token_type_ids.shape: (8598, 256)\n",
      "2020-06-16 18:22:51.530 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:156 - all_start_ids.shape: (8598, 256)\n",
      "2020-06-16 18:22:51.654 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:157 - all_end_ids.shape: (8598, 256)\n",
      "2020-06-16 18:22:51.660 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:158 - all_subjects_ids.shape: (8598,)\n",
      "2020-06-16 18:22:51.661 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:159 - all_input_lens.shape: (8598,)\n",
      "2020-06-16 18:22:52.173 | INFO     | theta.modeling.trainer:train:154 - Start training ...\n",
      "2020-06-16 18:22:52.174 | INFO     | theta.modeling.trainer:train:155 -   Num examples    = 8598\n",
      "2020-06-16 18:22:52.175 | INFO     | theta.modeling.trainer:train:156 -   Num epoch steps = 717\n",
      "2020-06-16 18:22:52.177 | INFO     | theta.modeling.trainer:train:157 -   Num epochs = 3\n",
      "2020-06-16 18:22:52.177 | INFO     | theta.modeling.trainer:train:158 -   Batch size = 12\n",
      "2020-06-16 18:22:52.178 | INFO     | theta.modeling.trainer:train:171 -   Gradient Accumulation steps = 1\n",
      "2020-06-16 18:22:52.179 | INFO     | theta.modeling.trainer:train:173 -   Total optimization steps = 2151\n",
      "2020-06-16 18:22:52.181 | INFO     | theta.modeling.ner_span.trainer:load_pretrained_model:195 - model_path: /opt/share/pretrained/pytorch/bert-base-chinese\n",
      "2020-06-16 18:22:52.182 | INFO     | theta.modeling.ner_span.trainer:load_pretrained_model:196 - config:BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"focalloss_alpha\": null,\n",
      "  \"focalloss_gamma\": 1.5,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"loss_type\": \"CrossEntropyLoss\",\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"soft_label\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch(1/3)   1/717 [..............................] - ETA: 1:49 - lr: 0.00e+00 - loss: 2.6310Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Epoch(1/3)   2/717 [..............................] - ETA: 1:39 - lr: 4.65e-08 - loss: 2.6897Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idleuncle/.pyenv/versions/env-nlp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/3)   3/717 [..............................] - ETA: 2:49 - lr: 9.30e-08 - loss: 2.6476Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch(1/3) 717/717 [==============================] - 111s 154ms/step - lr: 1.52e-05 - loss: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:24:47.644 | INFO     | theta.modeling.trainer:train:362 - Epoch(1/3) evaluating.\n",
      "Tokenize: 100%|██████████| 2150/2150 [00:00<00:00, 71416.44it/s]\n",
      "2020-06-16 18:24:47.818 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:151 - all_input_ids.shape: (2150, 256)\n",
      "2020-06-16 18:24:47.849 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:153 - all_attention_mask.shape: (2150, 256)\n",
      "2020-06-16 18:24:47.879 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:155 - all_token_type_ids.shape: (2150, 256)\n",
      "2020-06-16 18:24:47.910 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:156 - all_start_ids.shape: (2150, 256)\n",
      "2020-06-16 18:24:47.941 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:157 - all_end_ids.shape: (2150, 256)\n",
      "2020-06-16 18:24:47.943 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:158 - all_subjects_ids.shape: (2150,)\n",
      "2020-06-16 18:24:47.945 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:159 - all_input_lens.shape: (2150,)\n",
      "2020-06-16 18:24:48.068 | INFO     | theta.modeling.trainer:evaluate:445 - Start evaluating ...\n",
      "2020-06-16 18:24:48.069 | INFO     | theta.modeling.trainer:evaluate:446 -   Num examples    = 2150\n",
      "2020-06-16 18:24:48.070 | INFO     | theta.modeling.trainer:evaluate:447 -   Num epoch steps = 180\n",
      "2020-06-16 18:24:48.070 | INFO     | theta.modeling.trainer:evaluate:448 -   Batch size = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 180/180 [==============================] - 57s 314ms/step - acc: 0.7678 - recall: 0.7567 - f1: 0.7623 - loss: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:25:44.644 | INFO     | theta.utils.ner_utils:get_ner_results:13 - =======================================================\n",
      "2020-06-16 18:25:44.645 | INFO     | theta.utils.ner_utils:get_ner_results:14 -                                    acc    recall f1    \n",
      "2020-06-16 18:25:44.646 | INFO     | theta.utils.ner_utils:get_ner_results:15 - -------------------------------------------------------\n",
      "2020-06-16 18:25:44.647 | INFO     | theta.utils.ner_utils:get_ner_results:26 - name                             | 0.7709 0.9280 0.8422\n",
      "2020-06-16 18:25:44.648 | INFO     | theta.utils.ner_utils:get_ner_results:26 - book                             | 0.8689 0.7571 0.8092\n",
      "2020-06-16 18:25:44.649 | INFO     | theta.utils.ner_utils:get_ner_results:26 - position                         | 0.8155 0.7896 0.8024\n",
      "2020-06-16 18:25:44.650 | INFO     | theta.utils.ner_utils:get_ner_results:26 - game                             | 0.7543 0.8506 0.7996\n",
      "2020-06-16 18:25:44.651 | INFO     | theta.utils.ner_utils:get_ner_results:26 - company                          | 0.7532 0.8179 0.7842\n",
      "2020-06-16 18:25:44.652 | INFO     | theta.utils.ner_utils:get_ner_results:26 - organization                     | 0.7942 0.7618 0.7777\n",
      "2020-06-16 18:25:44.653 | INFO     | theta.utils.ner_utils:get_ner_results:26 - government                       | 0.7810 0.7563 0.7685\n",
      "2020-06-16 18:25:44.653 | INFO     | theta.utils.ner_utils:get_ner_results:26 - scene                            | 0.6602 0.7331 0.6948\n",
      "2020-06-16 18:25:44.655 | INFO     | theta.utils.ner_utils:get_ner_results:26 - movie                            | 0.8662 0.5714 0.6886\n",
      "2020-06-16 18:25:44.656 | INFO     | theta.utils.ner_utils:get_ner_results:26 - address                          | 0.6887 0.4448 0.5405\n",
      "2020-06-16 18:25:44.657 | INFO     | theta.utils.ner_utils:get_ner_results:27 - -------------------------------------------------------\n",
      "2020-06-16 18:25:44.658 | INFO     | theta.utils.ner_utils:get_ner_results:29 -                                  | 0.7678 0.7567 0.7623\n",
      "2020-06-16 18:25:44.659 | INFO     | theta.utils.ner_utils:get_ner_results:30 - -------------------------------------------------------\n",
      "2020-06-16 18:25:44.670 | INFO     | theta.modeling.trainer:train:400 - Best f1: 0.7623 (0.762257)\n",
      "2020-06-16 18:25:44.671 | INFO     | theta.modeling.trainer:save_model:114 - Saving model checkpoint to output_cluener/best_fold0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_acc\": \"0.767849\", \"eval_recall\": \"0.756745\", \"eval_f1\": \"0.762257\", \"learning_rate\": \"0.000015\", \"loss\": \"0.146133\", \"step\": 717}\n",
      " \n",
      "Epoch(2/3) 717/717 [==============================] - 110s 154ms/step - lr: 1.11e-05 - loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:27:42.665 | INFO     | theta.modeling.trainer:train:362 - Epoch(2/3) evaluating.\n",
      "Tokenize: 100%|██████████| 2150/2150 [00:00<00:00, 68638.71it/s]\n",
      "2020-06-16 18:27:42.843 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:151 - all_input_ids.shape: (2150, 256)\n",
      "2020-06-16 18:27:42.874 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:153 - all_attention_mask.shape: (2150, 256)\n",
      "2020-06-16 18:27:42.904 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:155 - all_token_type_ids.shape: (2150, 256)\n",
      "2020-06-16 18:27:42.936 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:156 - all_start_ids.shape: (2150, 256)\n",
      "2020-06-16 18:27:42.967 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:157 - all_end_ids.shape: (2150, 256)\n",
      "2020-06-16 18:27:42.969 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:158 - all_subjects_ids.shape: (2150,)\n",
      "2020-06-16 18:27:42.970 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:159 - all_input_lens.shape: (2150,)\n",
      "2020-06-16 18:27:43.096 | INFO     | theta.modeling.trainer:evaluate:445 - Start evaluating ...\n",
      "2020-06-16 18:27:43.097 | INFO     | theta.modeling.trainer:evaluate:446 -   Num examples    = 2150\n",
      "2020-06-16 18:27:43.098 | INFO     | theta.modeling.trainer:evaluate:447 -   Num epoch steps = 180\n",
      "2020-06-16 18:27:43.098 | INFO     | theta.modeling.trainer:evaluate:448 -   Batch size = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 180/180 [==============================] - 57s 314ms/step - acc: 0.7760 - recall: 0.7852 - f1: 0.7806 - loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:28:39.703 | INFO     | theta.utils.ner_utils:get_ner_results:13 - =======================================================\n",
      "2020-06-16 18:28:39.704 | INFO     | theta.utils.ner_utils:get_ner_results:14 -                                    acc    recall f1    \n",
      "2020-06-16 18:28:39.705 | INFO     | theta.utils.ner_utils:get_ner_results:15 - -------------------------------------------------------\n",
      "2020-06-16 18:28:39.705 | INFO     | theta.utils.ner_utils:get_ner_results:26 - name                             | 0.8329 0.9076 0.8687\n",
      "2020-06-16 18:28:39.706 | INFO     | theta.utils.ner_utils:get_ner_results:26 - book                             | 0.9244 0.7571 0.8325\n",
      "2020-06-16 18:28:39.707 | INFO     | theta.utils.ner_utils:get_ner_results:26 - game                             | 0.8071 0.8420 0.8242\n",
      "2020-06-16 18:28:39.707 | INFO     | theta.utils.ner_utils:get_ner_results:26 - position                         | 0.7961 0.8147 0.8053\n",
      "2020-06-16 18:28:39.708 | INFO     | theta.utils.ner_utils:get_ner_results:26 - company                          | 0.7884 0.8091 0.7986\n",
      "2020-06-16 18:28:39.709 | INFO     | theta.utils.ner_utils:get_ner_results:26 - movie                            | 0.7906 0.7773 0.7839\n",
      "2020-06-16 18:28:39.710 | INFO     | theta.utils.ner_utils:get_ner_results:26 - government                       | 0.7647 0.7816 0.7731\n",
      "2020-06-16 18:28:39.710 | INFO     | theta.utils.ner_utils:get_ner_results:26 - organization                     | 0.7489 0.7977 0.7725\n",
      "2020-06-16 18:28:39.711 | INFO     | theta.utils.ner_utils:get_ner_results:26 - scene                            | 0.7166 0.6748 0.6951\n",
      "2020-06-16 18:28:39.712 | INFO     | theta.utils.ner_utils:get_ner_results:26 - address                          | 0.6415 0.5890 0.6141\n",
      "2020-06-16 18:28:39.712 | INFO     | theta.utils.ner_utils:get_ner_results:27 - -------------------------------------------------------\n",
      "2020-06-16 18:28:39.713 | INFO     | theta.utils.ner_utils:get_ner_results:29 -                                  | 0.7760 0.7852 0.7806\n",
      "2020-06-16 18:28:39.714 | INFO     | theta.utils.ner_utils:get_ner_results:30 - -------------------------------------------------------\n",
      "2020-06-16 18:28:39.726 | INFO     | theta.modeling.trainer:train:400 - Best f1: 0.7806 (0.018346)\n",
      "2020-06-16 18:28:39.727 | INFO     | theta.modeling.trainer:save_model:114 - Saving model checkpoint to output_cluener/best_fold0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_acc\": \"0.776024\", \"eval_recall\": \"0.785236\", \"eval_f1\": \"0.780603\", \"learning_rate\": \"0.000007\", \"loss\": \"0.037003\", \"step\": 1434}\n",
      " \n",
      "Epoch(3/3) 717/717 [==============================] - 111s 155ms/step - lr: 3.71e-06 - loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:30:38.477 | INFO     | theta.modeling.trainer:train:362 - Epoch(3/3) evaluating.\n",
      "Tokenize: 100%|██████████| 2150/2150 [00:00<00:00, 70480.38it/s]\n",
      "2020-06-16 18:30:38.650 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:151 - all_input_ids.shape: (2150, 256)\n",
      "2020-06-16 18:30:38.681 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:153 - all_attention_mask.shape: (2150, 256)\n",
      "2020-06-16 18:30:38.711 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:155 - all_token_type_ids.shape: (2150, 256)\n",
      "2020-06-16 18:30:38.742 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:156 - all_start_ids.shape: (2150, 256)\n",
      "2020-06-16 18:30:38.773 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:157 - all_end_ids.shape: (2150, 256)\n",
      "2020-06-16 18:30:38.775 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:158 - all_subjects_ids.shape: (2150,)\n",
      "2020-06-16 18:30:38.776 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:159 - all_input_lens.shape: (2150,)\n",
      "2020-06-16 18:30:39.204 | INFO     | theta.modeling.trainer:evaluate:445 - Start evaluating ...\n",
      "2020-06-16 18:30:39.205 | INFO     | theta.modeling.trainer:evaluate:446 -   Num examples    = 2150\n",
      "2020-06-16 18:30:39.206 | INFO     | theta.modeling.trainer:evaluate:447 -   Num epoch steps = 180\n",
      "2020-06-16 18:30:39.207 | INFO     | theta.modeling.trainer:evaluate:448 -   Batch size = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 180/180 [==============================] - 56s 312ms/step - acc: 0.7745 - recall: 0.7835 - f1: 0.7790 - loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:31:35.399 | INFO     | theta.utils.ner_utils:get_ner_results:13 - =======================================================\n",
      "2020-06-16 18:31:35.400 | INFO     | theta.utils.ner_utils:get_ner_results:14 -                                    acc    recall f1    \n",
      "2020-06-16 18:31:35.400 | INFO     | theta.utils.ner_utils:get_ner_results:15 - -------------------------------------------------------\n",
      "2020-06-16 18:31:35.401 | INFO     | theta.utils.ner_utils:get_ner_results:26 - name                             | 0.8194 0.9062 0.8606\n",
      "2020-06-16 18:31:35.402 | INFO     | theta.utils.ner_utils:get_ner_results:26 - game                             | 0.8101 0.8312 0.8205\n",
      "2020-06-16 18:31:35.403 | INFO     | theta.utils.ner_utils:get_ner_results:26 - book                             | 0.8333 0.7857 0.8088\n",
      "2020-06-16 18:31:35.403 | INFO     | theta.utils.ner_utils:get_ner_results:26 - position                         | 0.8017 0.8097 0.8056\n",
      "2020-06-16 18:31:35.404 | INFO     | theta.utils.ner_utils:get_ner_results:26 - company                          | 0.7886 0.7968 0.7927\n",
      "2020-06-16 18:31:35.405 | INFO     | theta.utils.ner_utils:get_ner_results:26 - movie                            | 0.8035 0.7731 0.7880\n",
      "2020-06-16 18:31:35.405 | INFO     | theta.utils.ner_utils:get_ner_results:26 - government                       | 0.7754 0.7975 0.7863\n",
      "2020-06-16 18:31:35.406 | INFO     | theta.utils.ner_utils:get_ner_results:26 - organization                     | 0.7816 0.7765 0.7791\n",
      "2020-06-16 18:31:35.407 | INFO     | theta.utils.ner_utils:get_ner_results:26 - scene                            | 0.6901 0.6626 0.6761\n",
      "2020-06-16 18:31:35.407 | INFO     | theta.utils.ner_utils:get_ner_results:26 - address                          | 0.6372 0.6157 0.6262\n",
      "2020-06-16 18:31:35.408 | INFO     | theta.utils.ner_utils:get_ner_results:27 - -------------------------------------------------------\n",
      "2020-06-16 18:31:35.409 | INFO     | theta.utils.ner_utils:get_ner_results:29 -                                  | 0.7745 0.7835 0.7790\n",
      "2020-06-16 18:31:35.409 | INFO     | theta.utils.ner_utils:get_ner_results:30 - -------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_acc\": \"0.774483\", \"eval_recall\": \"0.783510\", \"eval_f1\": \"0.778970\", \"learning_rate\": \"0.000000\", \"loss\": \"0.025855\", \"step\": 2151}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "args.do_train=True\n",
    "args.do_predict=False\n",
    "args.do_eval=False\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 启动推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:32:31.465 | INFO     | theta.modeling.ner_span.trainer:init_labels:283 - args.label2id: {'[unused1]': 0, 'address': 1, 'book': 2, 'company': 3, 'game': 4, 'government': 5, 'movie': 6, 'name': 7, 'organization': 8, 'position': 9, 'scene': 10}\n",
      "2020-06-16 18:32:31.466 | INFO     | theta.modeling.ner_span.trainer:init_labels:284 - args.id2label: {0: '[unused1]', 1: 'address', 2: 'book', 3: 'company', 4: 'game', 5: 'government', 6: 'movie', 7: 'name', 8: 'organization', 9: 'position', 10: 'scene'}\n",
      "2020-06-16 18:32:31.468 | INFO     | theta.modeling.ner_span.trainer:init_labels:285 - args.num_labels: 11\n",
      "100%|██████████| 1345/1345 [00:00<00:00, 260473.68it/s]\n",
      "100%|██████████| 1345/1345 [00:00<00:00, 356122.65it/s]\n",
      "2020-06-16 18:32:31.501 | INFO     | theta.modeling.ner_utils:load_ner_examples:410 - Loaded 1345 examples.\n",
      "2020-06-16 18:32:31.501 | INFO     | __main__:load_test_examples:91 - Loaded 1345 test examples.\n",
      "2020-06-16 18:32:31.504 | INFO     | theta.modeling.ner_span.trainer:load_pretrained_model:195 - model_path: output_cluener/best_fold0\n",
      "2020-06-16 18:32:31.505 | INFO     | theta.modeling.ner_span.trainer:load_pretrained_model:196 - config:BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertSpanForNer\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"focalloss_alpha\": null,\n",
      "  \"focalloss_gamma\": 1.5,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"loss_type\": \"CrossEntropyLoss\",\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"soft_label\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1345\n",
      "[{'id': 0, 'text': '四川敦煌学”。近年来，丹棱县等地一些不知名的石窟迎来了海内外的游客，他们随身携带着胡文和的著作。'}, {'id': 1, 'text': '尼日利亚海军发言人当天在阿布贾向尼日利亚通讯社证实了这一消息。'}, {'id': 2, 'text': '销售冠军：辐射3-Bethesda'}, {'id': 3, 'text': '所以大多数人都是从巴厘岛南部开始环岛之旅。'}, {'id': 4, 'text': '备受瞩目的动作及冒险类大作《迷失》在其英文版上市之初就受到了全球玩家的大力追捧。'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenize: 100%|██████████| 1345/1345 [00:00<00:00, 70311.08it/s]\n",
      "2020-06-16 18:32:36.226 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:151 - all_input_ids.shape: (1345, 256)\n",
      "2020-06-16 18:32:36.245 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:153 - all_attention_mask.shape: (1345, 256)\n",
      "2020-06-16 18:32:36.265 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:155 - all_token_type_ids.shape: (1345, 256)\n",
      "2020-06-16 18:32:36.284 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:156 - all_start_ids.shape: (1345, 256)\n",
      "2020-06-16 18:32:36.303 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:157 - all_end_ids.shape: (1345, 256)\n",
      "2020-06-16 18:32:36.304 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:158 - all_subjects_ids.shape: (1345, 0)\n",
      "2020-06-16 18:32:36.305 | DEBUG    | theta.modeling.ner_span.dataset:encode_examples:159 - all_input_lens.shape: (1345,)\n",
      "2020-06-16 18:32:36.383 | INFO     | theta.modeling.trainer:predict:505 - Start predicting ...\n",
      "2020-06-16 18:32:36.384 | INFO     | theta.modeling.trainer:predict:506 -   Num examples    = 1345\n",
      "2020-06-16 18:32:36.384 | INFO     | theta.modeling.trainer:predict:507 -   Num epoch steps = 113\n",
      "2020-06-16 18:32:36.385 | INFO     | theta.modeling.trainer:predict:508 -   Batch size = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 113/113 [==============================] - 35s 311ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1345it [00:00, 44595.56it/s]\n",
      "2020-06-16 18:33:11.564 | INFO     | theta.modeling.ner_utils:save_ner_preds:174 - Reviews file: output_cluener/cluener_reviews_fold0.json\n",
      "2020-06-16 18:33:11.567 | INFO     | theta.modeling.ner_utils:save_ner_preds:185 - Total 10 categories and 2123 mentions saved to output_cluener/cluener_category_mentions_fold0.txt\n"
     ]
    }
   ],
   "source": [
    "args.do_train=False\n",
    "args.do_predict=True\n",
    "args.do_eval=False\n",
    "args.model_path=CHECKPOINT_MODEL\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 生成提交结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 18:33:14.318 | INFO     | __main__:generate_submission:43 - Saved 1345 lines in cluener_predict.json\n"
     ]
    }
   ],
   "source": [
    "args.do_train=False\n",
    "args.do_predict=False\n",
    "args.do_eval=False\n",
    "args.model_path=CHECKPOINT_MODEL\n",
    "args.generate_submission = True\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-nlp",
   "language": "python",
   "name": "env-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
